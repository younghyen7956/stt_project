{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8630b0d-fcf6-496d-846f-a96a7c881ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì‚¬ìš© ì¥ì¹˜: mps\n",
      "ğŸ’¡ ì‚¬ìš© ë°ì´í„° íƒ€ì…: torch.float16\n",
      "ëª¨ë¸ (openai/whisper-large-v3-turbo) ë¡œë”© ì¤‘... (ì¥ì¹˜: mps, ë°ì´í„° íƒ€ì…: torch.float16)\n",
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í”„ë¡œì„¸ì„œ ë¡œë”© ì™„ë£Œ\n",
      "âœ… ìŒì„± ì¸ì‹ íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "# from datasets import load_dataset # ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ\n",
    "import soundfile as sf\n",
    "import numpy as np # <--- [ìˆ˜ì • 1] numpy ì„í¬íŠ¸ ì¶”ê°€\n",
    "import tqdm # tqdm ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "\n",
    "# --- (ì´ì „ ì½”ë“œëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€) ---\n",
    "# 1. ì¥ì¹˜ ì„¤ì •\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    torch_dtype = torch.float16\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    torch_dtype = torch.float16\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    torch_dtype = torch.float32\n",
    "\n",
    "print(f\"ğŸš€ ì‚¬ìš© ì¥ì¹˜: {device}\")\n",
    "print(f\"ğŸ’¡ ì‚¬ìš© ë°ì´í„° íƒ€ì…: {torch_dtype}\")\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\" # ë˜ëŠ” ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ID\n",
    "\n",
    "# 2. ëª¨ë¸ ë¡œë“œ\n",
    "print(f\"ëª¨ë¸ ({model_id}) ë¡œë”© ì¤‘... (ì¥ì¹˜: {device}, ë°ì´í„° íƒ€ì…: {torch_dtype})\")\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True if device == \"cpu\" else False,\n",
    "    use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ\")\n",
    "\n",
    "# 3. í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "print(\"âœ… í”„ë¡œì„¸ì„œ ë¡œë”© ì™„ë£Œ\")\n",
    "\n",
    "# 4. íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    return_timestamps=True\n",
    ")\n",
    "print(\"âœ… ìŒì„± ì¸ì‹ íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4439ced1-535d-45fa-a634-b395fa18dedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¡œì»¬ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë”© ì¤‘: /Users/gim-yonghyeon/Downloads/á„†á…¦á†¨á„‰á…µá„á…© á„‰á…³á„‘á…¦á„‹á…µá†«á„‹á…¥.mp3\n",
      "ì˜¤ë””ì˜¤ ë°°ì—´ì„ float32ë¡œ ë³€í™˜ ì¤‘ (í˜„ì¬ dtype: float64)\n",
      "ìŠ¤í…Œë ˆì˜¤ ì˜¤ë””ì˜¤(ì±„ë„ ìˆ˜: 2)ë¥¼ ëª¨ë…¸ë¡œ ë³€í™˜ ì¤‘...\n",
      "âœ… ë¡œì»¬ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë”© ì™„ë£Œ: /Users/gim-yonghyeon/Downloads/á„†á…¦á†¨á„‰á…µá„á…© á„‰á…³á„‘á…¦á„‹á…µá†«á„‹á…¥.mp3\n",
      "   ì˜¤ë””ì˜¤ ê¸¸ì´ (ìƒ˜í”Œ ìˆ˜): 783360\n",
      "   ìƒ˜í”Œë§ ë ˆì´íŠ¸: 44100 Hz\n",
      "   ì˜¤ë””ì˜¤ ë°°ì—´ dtype: float32\n",
      "\n",
      "ğŸ”¥ ì›Œë°ì—… ë‹¨ê³„ ì‹œì‘ (ëª¨ë¸ ìµœì í™”ë¥¼ ìœ„í•´ ëª‡ ì°¨ë¡€ ì‹¤í–‰)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warm-up step: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì›Œë°ì—… ì™„ë£Œ\n",
      "\n",
      "ğŸš€ ìµœì¢… ìŒì„± ì¸ì‹ ì‹¤í–‰...\n",
      "\n",
      "ğŸ“„ ìµœì¢… ë³€í™˜ëœ í…ìŠ¤íŠ¸:\n",
      "{'text': ' Empezando la grabaciÃ³n de voz. Suspendiendo la grabaciÃ³n de voz. Activando el modo de aparcamiento. El modo de aparcamiento se ha desactivado. Formateando la tarjeta SD. Inalizando la tarjeta SD. Cambiar la tarjeta SD.', 'chunks': [{'timestamp': (0.0, 1.88), 'text': ' Empezando la grabaciÃ³n de voz.'}, {'timestamp': (2.46, 4.24), 'text': ' Suspendiendo la grabaciÃ³n de voz.'}, {'timestamp': (4.88, 6.8), 'text': ' Activando el modo de aparcamiento.'}, {'timestamp': (7.32, 9.9), 'text': ' El modo de aparcamiento se ha desactivado.'}, {'timestamp': (10.38, 12.18), 'text': ' Formateando la tarjeta SD.'}, {'timestamp': (12.88, 14.86), 'text': ' Inalizando la tarjeta SD.'}, {'timestamp': (15.68, 17.46), 'text': ' Cambiar la tarjeta SD.'}]}\n"
     ]
    }
   ],
   "source": [
    "# your_audio_file_path = \"/Users/gim-yonghyeon/Documents/GitHub/stt_project/á„€á…ªá†¼á„’á…ªá„†á…®á†«á„Œá…¡á„‰á…¢á†¼á„’á…¡á†«á„‡á…¡á†¼á„‡á…§á†¼á„‹á…¯á†«_1.mp3\"\n",
    "your_audio_file_path = \"/Users/gim-yonghyeon/Downloads/á„†á…¦á†¨á„‰á…µá„á…© á„‰á…³á„‘á…¦á„‹á…µá†«á„‹á…¥.mp3\"\n",
    "\n",
    "try:\n",
    "    print(f\"ë¡œì»¬ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë”© ì¤‘: {your_audio_file_path}\")\n",
    "    if your_audio_file_path == \"YOUR_AUDIO_FILE.wav\":\n",
    "        raise FileNotFoundError(\"ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”. 'YOUR_AUDIO_FILE.wav'ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤.\")\n",
    "    audio_array, sampling_rate = sf.read(your_audio_file_path)\n",
    "    if audio_array.dtype != np.float32:\n",
    "        print(f\"ì˜¤ë””ì˜¤ ë°°ì—´ì„ float32ë¡œ ë³€í™˜ ì¤‘ (í˜„ì¬ dtype: {audio_array.dtype})\")\n",
    "        audio_array = audio_array.astype(np.float32)\n",
    "    if audio_array.ndim > 1 and audio_array.shape[1] > 1:\n",
    "        print(f\"ìŠ¤í…Œë ˆì˜¤ ì˜¤ë””ì˜¤(ì±„ë„ ìˆ˜: {audio_array.shape[1]})ë¥¼ ëª¨ë…¸ë¡œ ë³€í™˜ ì¤‘...\")\n",
    "        audio_array = np.mean(audio_array, axis=1)\n",
    "    loaded_audio_sample = {\n",
    "        \"path\": your_audio_file_path,\n",
    "        \"array\": audio_array,\n",
    "        \"sampling_rate\": sampling_rate\n",
    "    }\n",
    "    print(f\"âœ… ë¡œì»¬ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë”© ì™„ë£Œ: {loaded_audio_sample['path']}\")\n",
    "    print(f\"   ì˜¤ë””ì˜¤ ê¸¸ì´ (ìƒ˜í”Œ ìˆ˜): {len(loaded_audio_sample['array'])}\")\n",
    "    print(f\"   ìƒ˜í”Œë§ ë ˆì´íŠ¸: {loaded_audio_sample['sampling_rate']} Hz\")\n",
    "    print(f\"   ì˜¤ë””ì˜¤ ë°°ì—´ dtype: {loaded_audio_sample['array'].dtype}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ íŒŒì¼ ì˜¤ë¥˜: {e}\")\n",
    "    print(\"ì§€ì •í•œ ê²½ë¡œì— ì˜¤ë””ì˜¤ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(\"ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ í˜•ì‹(ì˜ˆ: WAV, MP3, FLAC ë“±)ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    print(\"ë‹¤ì–‘í•œ ì˜¤ë””ì˜¤ í˜•ì‹ì„ ì§€ì›í•˜ë ¤ë©´ ì‹œìŠ¤í…œì— FFmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "    exit()\n",
    "\n",
    "# --- [ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘] ---\n",
    "\n",
    "# sdpa_kernelê³¼ SDPBackendë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ìƒë‹¨ì— import êµ¬ë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "# ì˜ˆ: from torch.nn.attention import sdpa_kernel, SDPBackend\n",
    "# ë§Œì•½ ì´ ê¸°ëŠ¥ì´ í™•ì‹¤í•˜ì§€ ì•Šë‹¤ë©´, ì•„ë˜ 'with sdpa_kernel(...)' ì¤„ë“¤ì„ ì œê±°í•˜ê³ \n",
    "# 'pipe' í•¨ìˆ˜ í˜¸ì¶œë§Œ ë‚¨ê²¨ë„ ê¸°ë³¸ì ì¸ ë™ì‘ì—ëŠ” ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "print(\"\\nğŸ”¥ ì›Œë°ì—… ë‹¨ê³„ ì‹œì‘ (ëª¨ë¸ ìµœì í™”ë¥¼ ìœ„í•´ ëª‡ ì°¨ë¡€ ì‹¤í–‰)...\")\n",
    "try:\n",
    "    if 'loaded_audio_sample' in locals(): # ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "        # tqdm ì‚¬ìš©ë²• ìˆ˜ì • ë° ì˜¬ë°”ë¥¸ ë³€ìˆ˜ëª… ì‚¬ìš©\n",
    "        for _ in tqdm.tqdm(range(2), desc=\"Warm-up step\"): # <--- [ìˆ˜ì • 2] tqdm.tqdm()ìœ¼ë¡œ ë³€ê²½\n",
    "            # loaded_audio_sample ì‚¬ìš©, ë¶ˆí•„ìš”í•  ìˆ˜ ìˆëŠ” generate_kwargs ì œê±° (ë‹¨ìˆœ ì›Œë°ì—…)\n",
    "            _ = pipe(loaded_audio_sample.copy()) # <--- [ìˆ˜ì • 3] sample -> loaded_audio_sample\n",
    "        print(\"âœ… ì›Œë°ì—… ì™„ë£Œ\")\n",
    "\n",
    "        print(\"\\nğŸš€ ìµœì¢… ìŒì„± ì¸ì‹ ì‹¤í–‰...\")\n",
    "        # ì—¬ê¸°ë„ loaded_audio_sample ì‚¬ìš©\n",
    "        result = pipe(loaded_audio_sample.copy(), generate_kwargs={\"language\": None}) # <--- [ìˆ˜ì • 3] sample -> loaded_audio_sample\n",
    "\n",
    "        print(\"\\nğŸ“„ ìµœì¢… ë³€í™˜ëœ í…ìŠ¤íŠ¸:\")\n",
    "        print(result)\n",
    "    else:\n",
    "        print(\"âŒ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ìŒì„± ì¸ì‹ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "except NameError as e:\n",
    "    # sdpa_kernel ë“±ì´ importë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ë°œìƒ ê°€ëŠ¥\n",
    "    print(f\"âŒ ì‹¤í–‰ ì¤‘ ë³€ìˆ˜ ì´ë¦„ ê´€ë ¨ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(\"   'sdpa_kernel' ë˜ëŠ” 'SDPBackend' ê°™ì€ íŠ¹ë³„í•œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ í–ˆë‹¤ë©´, í•´ë‹¹ ê¸°ëŠ¥ì´ ì˜¬ë°”ë¥´ê²Œ import ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    print(\"   ë˜ëŠ” í•´ë‹¹ ì½”ë“œ ë¼ì¸ì„ ì¼ì‹œì ìœ¼ë¡œ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì œê±°í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ìŒì„± ì¸ì‹ ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "# --- [ìˆ˜ì •ëœ ë¶€ë¶„ ë] ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "521d5c88-3362-48e0-a68e-a2efec61b37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' Empezando la grabaciÃ³n de voz. Suspendiendo la grabaciÃ³n de voz. Activando el modo de aparcamiento. El modo de aparcamiento se ha desactivado. Formateando la tarjeta SD. Inalizando la tarjeta SD. Cambiar la tarjeta SD.',\n",
       " 'chunks': [{'timestamp': (0.0, 1.88),\n",
       "   'text': ' Empezando la grabaciÃ³n de voz.'},\n",
       "  {'timestamp': (2.46, 4.24), 'text': ' Suspendiendo la grabaciÃ³n de voz.'},\n",
       "  {'timestamp': (4.88, 6.8), 'text': ' Activando el modo de aparcamiento.'},\n",
       "  {'timestamp': (7.32, 9.9),\n",
       "   'text': ' El modo de aparcamiento se ha desactivado.'},\n",
       "  {'timestamp': (10.38, 12.18), 'text': ' Formateando la tarjeta SD.'},\n",
       "  {'timestamp': (12.88, 14.86), 'text': ' Inalizando la tarjeta SD.'},\n",
       "  {'timestamp': (15.68, 17.46), 'text': ' Cambiar la tarjeta SD.'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463a922-5a4a-4377-8037-076a2739204c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c8f2be-3ce5-40a7-bc85-4543ac3af054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: /Users/gim-yonghyeon/Downloads/ê´‘í™”ë¬¸ììƒí•œë°©ë³‘ì›_1.mp3, ìƒ˜í”Œë§ ë ˆì´íŠ¸: 44100\n",
      "ì˜¤ë””ì˜¤ íƒ€ì…ì„ np.float32ë¡œ ë³€í™˜ ì¤‘ (í˜„ì¬ íƒ€ì…: float64)\n",
      "Whisper íŒŒì´í”„ë¼ì¸ ìƒì„± ì¤‘ (ëª¨ë¸: openai/whisper-large-v3-turbo, ì¥ì¹˜: mps)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ.\n",
      "\n",
      "ğŸ”¥ ì›Œë°ì—… ë‹¨ê³„ ì‹œì‘ (ëª¨ë¸ ìµœì í™”ë¥¼ ìœ„í•´ ëª‡ ì°¨ë¡€ ì‹¤í–‰)...\n",
      "Warm-up run #1...\n",
      "Warm-up run #2...\n",
      "âœ… ì›Œë°ì—… ì™„ë£Œ\n",
      "\n",
      "ğŸš€ ì˜¤ë””ì˜¤ -> í•œêµ­ì–´ ì „ì‚¬ ì‘ì—… ì‹¤í–‰ ì¤‘...\n",
      "Whisper output (Korean Transcription):  ì±…ì£¼ ë””ìŠ¤í¬ ê°€ìŠ´ìˆ˜ì¶œì„ ì˜ì–‘ì€ ììƒí™˜ë™ë³‘ì—°ìœ¼ë¡œ ê°€ì…¨ë‹¤ë©´ ì†Œê°ì˜ì—­ 6ë²ˆ ì¶œê³ ë¥¼ ë‚˜ê°€ì‹œê¸¸ ë°”ëë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import torch # torch ê°€ìš© ì—¬ë¶€ì— ë”°ë¼ device ì„¤ì •\n",
    "\n",
    "stt_model_name = \"openai/whisper-large-v3-turbo\" # ë˜ëŠ” \"openai/whisper-large-v3\" ì‚¬ìš© ê¶Œì¥\n",
    "audio_file_path = \"/Users/gim-yonghyeon/Downloads/ê´‘í™”ë¬¸ììƒí•œë°©ë³‘ì›_1.mp3\" # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"MPS ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"CUDA ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "try:\n",
    "    audio_input, sample_rate = sf.read(audio_file_path)\n",
    "    print(f\"ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {audio_file_path}, ìƒ˜í”Œë§ ë ˆì´íŠ¸: {sample_rate}\")\n",
    "\n",
    "    if audio_input.ndim > 1: \n",
    "        print(f\"ì˜¤ë””ì˜¤ë¥¼ ëª¨ë…¸ë¡œ ë³€í™˜ ì¤‘ (ì±„ë„ ìˆ˜: {audio_input.shape[1]})\")\n",
    "        audio_input = np.mean(audio_input, axis=1)\n",
    "    \n",
    "    if audio_input.dtype != np.float32:\n",
    "        print(f\"ì˜¤ë””ì˜¤ íƒ€ì…ì„ np.float32ë¡œ ë³€í™˜ ì¤‘ (í˜„ì¬ íƒ€ì…: {audio_input.dtype})\")\n",
    "        audio_input = audio_input.astype(np.float32)\n",
    "        \n",
    "    # 1. Whisper íŒŒì´í”„ë¼ì¸ ìƒì„± (ì›Œë°ì—… ì „ì— ìƒì„±!)\n",
    "    # 1. Whisper íŒŒì´í”„ë¼ì¸ ìƒì„± (ì›Œë°ì—… ì „ì— ìƒì„±!)\n",
    "    print(f\"Whisper íŒŒì´í”„ë¼ì¸ ìƒì„± ì¤‘ (ëª¨ë¸: {stt_model_name}, ì¥ì¹˜: {device})...\")\n",
    "    whisper_pipeline = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=stt_model_name,\n",
    "        torch_dtype=torch.float16 if device == \"mps\" else torch.float32,\n",
    "        device=device,\n",
    "        return_timestamps=True  # <--- ì—¬ê¸°ì—ë„ ì¶”ê°€! (ìŠ¤í¬ë¦½íŠ¸ 1ê³¼ ë™ì¼í•˜ê²Œ)\n",
    "    )\n",
    "    print(\"Whisper íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ.\")\n",
    "\n",
    "    # 2. ì›Œë°ì—… ë‹¨ê³„ ì‹œì‘\n",
    "    print(\"\\nğŸ”¥ ì›Œë°ì—… ë‹¨ê³„ ì‹œì‘ (ëª¨ë¸ ìµœì í™”ë¥¼ ìœ„í•´ ëª‡ ì°¨ë¡€ ì‹¤í–‰)...\")\n",
    "    for i in range(2):\n",
    "        print(f\"Warm-up run #{i+1}...\")\n",
    "        # return_timestampsëŠ” íŒŒì´í”„ë¼ì¸ ìƒì„±ì‹œ ì„¤ì •í–ˆìœ¼ë¯€ë¡œ í˜¸ì¶œì‹œì—” ìƒëµ ê°€ëŠ¥ (ë˜ëŠ” ì¼ê´€ì„± ìœ„í•´ True ì „ë‹¬ë„ ë¬´ë°©)\n",
    "        _ = whisper_pipeline(audio_input.copy()) \n",
    "    print(\"âœ… ì›Œë°ì—… ì™„ë£Œ\")\n",
    "\n",
    "    # 3. ì‹¤ì œ ìŒì„± ì¸ì‹ ì‘ì—… ì‹¤í–‰ (í•œêµ­ì–´ ì „ì‚¬)\n",
    "    print(\"\\nğŸš€ ì˜¤ë””ì˜¤ -> í•œêµ­ì–´ ì „ì‚¬ ì‘ì—… ì‹¤í–‰ ì¤‘...\")\n",
    "    result = whisper_pipeline(\n",
    "        audio_input.copy()\n",
    "    )\n",
    "    transcribed_text = result['text']\n",
    "    print(f\"Whisper output (Korean Transcription): {transcribed_text}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ì˜¤ë¥˜: ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {audio_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbbcde-5fd9-4eaa-87dd-0672f3aea819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stt_project)",
   "language": "python",
   "name": "stt_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
