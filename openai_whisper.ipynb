{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8630b0d-fcf6-496d-846f-a96a7c881ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 사용 장치: mps\n",
      "💡 사용 데이터 타입: torch.float16\n",
      "모델 (openai/whisper-large-v3-turbo) 로딩 중... (장치: mps, 데이터 타입: torch.float16)\n",
      "✅ 모델 로딩 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 프로세서 로딩 완료\n",
      "✅ 음성 인식 파이프라인 생성 완료\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "# from datasets import load_dataset # 더 이상 사용하지 않음\n",
    "import soundfile as sf\n",
    "import numpy as np # <--- [수정 1] numpy 임포트 추가\n",
    "import tqdm # tqdm 모듈 임포트\n",
    "\n",
    "# --- (이전 코드는 동일하게 유지) ---\n",
    "# 1. 장치 설정\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    torch_dtype = torch.float16\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    torch_dtype = torch.float16\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    torch_dtype = torch.float32\n",
    "\n",
    "print(f\"🚀 사용 장치: {device}\")\n",
    "print(f\"💡 사용 데이터 타입: {torch_dtype}\")\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\" # 또는 사용 중인 모델 ID\n",
    "\n",
    "# 2. 모델 로드\n",
    "print(f\"모델 ({model_id}) 로딩 중... (장치: {device}, 데이터 타입: {torch_dtype})\")\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True if device == \"cpu\" else False,\n",
    "    use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "print(\"✅ 모델 로딩 완료\")\n",
    "\n",
    "# 3. 프로세서 로드\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "print(\"✅ 프로세서 로딩 완료\")\n",
    "\n",
    "# 4. 파이프라인 생성\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    return_timestamps=True\n",
    ")\n",
    "print(\"✅ 음성 인식 파이프라인 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4439ced1-535d-45fa-a634-b395fa18dedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로컬 오디오 파일 로딩 중: /Users/gim-yonghyeon/Downloads/멕시코 스페인어.mp3\n",
      "오디오 배열을 float32로 변환 중 (현재 dtype: float64)\n",
      "스테레오 오디오(채널 수: 2)를 모노로 변환 중...\n",
      "✅ 로컬 오디오 파일 로딩 완료: /Users/gim-yonghyeon/Downloads/멕시코 스페인어.mp3\n",
      "   오디오 길이 (샘플 수): 783360\n",
      "   샘플링 레이트: 44100 Hz\n",
      "   오디오 배열 dtype: float32\n",
      "\n",
      "🔥 워밍업 단계 시작 (모델 최적화를 위해 몇 차례 실행)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warm-up step: 100%|███████████████████████████████| 2/2 [00:06<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 워밍업 완료\n",
      "\n",
      "🚀 최종 음성 인식 실행...\n",
      "\n",
      "📄 최종 변환된 텍스트:\n",
      "{'text': ' Empezando la grabación de voz. Suspendiendo la grabación de voz. Activando el modo de aparcamiento. El modo de aparcamiento se ha desactivado. Formateando la tarjeta SD. Inalizando la tarjeta SD. Cambiar la tarjeta SD.', 'chunks': [{'timestamp': (0.0, 1.88), 'text': ' Empezando la grabación de voz.'}, {'timestamp': (2.46, 4.24), 'text': ' Suspendiendo la grabación de voz.'}, {'timestamp': (4.88, 6.8), 'text': ' Activando el modo de aparcamiento.'}, {'timestamp': (7.32, 9.9), 'text': ' El modo de aparcamiento se ha desactivado.'}, {'timestamp': (10.38, 12.18), 'text': ' Formateando la tarjeta SD.'}, {'timestamp': (12.88, 14.86), 'text': ' Inalizando la tarjeta SD.'}, {'timestamp': (15.68, 17.46), 'text': ' Cambiar la tarjeta SD.'}]}\n"
     ]
    }
   ],
   "source": [
    "# your_audio_file_path = \"/Users/gim-yonghyeon/Documents/GitHub/stt_project/광화문자생한방병원_1.mp3\"\n",
    "your_audio_file_path = \"/Users/gim-yonghyeon/Downloads/멕시코 스페인어.mp3\"\n",
    "\n",
    "try:\n",
    "    print(f\"로컬 오디오 파일 로딩 중: {your_audio_file_path}\")\n",
    "    if your_audio_file_path == \"YOUR_AUDIO_FILE.wav\":\n",
    "        raise FileNotFoundError(\"오디오 파일 경로를 실제 파일 경로로 수정해주세요. 'YOUR_AUDIO_FILE.wav'는 예시입니다.\")\n",
    "    audio_array, sampling_rate = sf.read(your_audio_file_path)\n",
    "    if audio_array.dtype != np.float32:\n",
    "        print(f\"오디오 배열을 float32로 변환 중 (현재 dtype: {audio_array.dtype})\")\n",
    "        audio_array = audio_array.astype(np.float32)\n",
    "    if audio_array.ndim > 1 and audio_array.shape[1] > 1:\n",
    "        print(f\"스테레오 오디오(채널 수: {audio_array.shape[1]})를 모노로 변환 중...\")\n",
    "        audio_array = np.mean(audio_array, axis=1)\n",
    "    loaded_audio_sample = {\n",
    "        \"path\": your_audio_file_path,\n",
    "        \"array\": audio_array,\n",
    "        \"sampling_rate\": sampling_rate\n",
    "    }\n",
    "    print(f\"✅ 로컬 오디오 파일 로딩 완료: {loaded_audio_sample['path']}\")\n",
    "    print(f\"   오디오 길이 (샘플 수): {len(loaded_audio_sample['array'])}\")\n",
    "    print(f\"   샘플링 레이트: {loaded_audio_sample['sampling_rate']} Hz\")\n",
    "    print(f\"   오디오 배열 dtype: {loaded_audio_sample['array'].dtype}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ 파일 오류: {e}\")\n",
    "    print(\"지정한 경로에 오디오 파일이 있는지 확인해주세요.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"❌ 오디오 파일 로드 중 오류 발생: {e}\")\n",
    "    print(\"지원되는 오디오 파일 형식(예: WAV, MP3, FLAC 등)인지 확인해주세요.\")\n",
    "    print(\"다양한 오디오 형식을 지원하려면 시스템에 FFmpeg가 설치되어 있어야 합니다.\")\n",
    "    exit()\n",
    "\n",
    "# --- [수정된 부분 시작] ---\n",
    "\n",
    "# sdpa_kernel과 SDPBackend를 사용하려면 상단에 import 구문이 필요합니다.\n",
    "# 예: from torch.nn.attention import sdpa_kernel, SDPBackend\n",
    "# 만약 이 기능이 확실하지 않다면, 아래 'with sdpa_kernel(...)' 줄들을 제거하고\n",
    "# 'pipe' 함수 호출만 남겨도 기본적인 동작에는 문제가 없습니다.\n",
    "\n",
    "print(\"\\n🔥 워밍업 단계 시작 (모델 최적화를 위해 몇 차례 실행)...\")\n",
    "try:\n",
    "    if 'loaded_audio_sample' in locals(): # 오디오 파일이 성공적으로 로드되었는지 확인\n",
    "        # tqdm 사용법 수정 및 올바른 변수명 사용\n",
    "        for _ in tqdm.tqdm(range(2), desc=\"Warm-up step\"): # <--- [수정 2] tqdm.tqdm()으로 변경\n",
    "            # loaded_audio_sample 사용, 불필요할 수 있는 generate_kwargs 제거 (단순 워밍업)\n",
    "            _ = pipe(loaded_audio_sample.copy()) # <--- [수정 3] sample -> loaded_audio_sample\n",
    "        print(\"✅ 워밍업 완료\")\n",
    "\n",
    "        print(\"\\n🚀 최종 음성 인식 실행...\")\n",
    "        # 여기도 loaded_audio_sample 사용\n",
    "        result = pipe(loaded_audio_sample.copy(), generate_kwargs={\"language\": None}) # <--- [수정 3] sample -> loaded_audio_sample\n",
    "\n",
    "        print(\"\\n📄 최종 변환된 텍스트:\")\n",
    "        print(result)\n",
    "    else:\n",
    "        print(\"❌ 오디오 데이터가 로드되지 않아 음성 인식을 진행할 수 없습니다.\")\n",
    "\n",
    "except NameError as e:\n",
    "    # sdpa_kernel 등이 import되지 않았을 경우 발생 가능\n",
    "    print(f\"❌ 실행 중 변수 이름 관련 오류 발생: {e}\")\n",
    "    print(\"   'sdpa_kernel' 또는 'SDPBackend' 같은 특별한 기능을 사용하려 했다면, 해당 기능이 올바르게 import 되었는지 확인해주세요.\")\n",
    "    print(\"   또는 해당 코드 라인을 일시적으로 주석 처리하거나 제거하고 다시 시도해보세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 음성 인식 실행 중 예상치 못한 오류 발생: {e}\")\n",
    "\n",
    "# --- [수정된 부분 끝] ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "521d5c88-3362-48e0-a68e-a2efec61b37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' Empezando la grabación de voz. Suspendiendo la grabación de voz. Activando el modo de aparcamiento. El modo de aparcamiento se ha desactivado. Formateando la tarjeta SD. Inalizando la tarjeta SD. Cambiar la tarjeta SD.',\n",
       " 'chunks': [{'timestamp': (0.0, 1.88),\n",
       "   'text': ' Empezando la grabación de voz.'},\n",
       "  {'timestamp': (2.46, 4.24), 'text': ' Suspendiendo la grabación de voz.'},\n",
       "  {'timestamp': (4.88, 6.8), 'text': ' Activando el modo de aparcamiento.'},\n",
       "  {'timestamp': (7.32, 9.9),\n",
       "   'text': ' El modo de aparcamiento se ha desactivado.'},\n",
       "  {'timestamp': (10.38, 12.18), 'text': ' Formateando la tarjeta SD.'},\n",
       "  {'timestamp': (12.88, 14.86), 'text': ' Inalizando la tarjeta SD.'},\n",
       "  {'timestamp': (15.68, 17.46), 'text': ' Cambiar la tarjeta SD.'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463a922-5a4a-4377-8037-076a2739204c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c8f2be-3ce5-40a7-bc85-4543ac3af054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS 장치를 사용합니다.\n",
      "오디오 파일 로드 완료: /Users/gim-yonghyeon/Downloads/광화문자생한방병원_1.mp3, 샘플링 레이트: 44100\n",
      "오디오 타입을 np.float32로 변환 중 (현재 타입: float64)\n",
      "Whisper 파이프라인 생성 중 (모델: openai/whisper-large-v3-turbo, 장치: mps)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper 파이프라인 생성 완료.\n",
      "\n",
      "🔥 워밍업 단계 시작 (모델 최적화를 위해 몇 차례 실행)...\n",
      "Warm-up run #1...\n",
      "Warm-up run #2...\n",
      "✅ 워밍업 완료\n",
      "\n",
      "🚀 오디오 -> 한국어 전사 작업 실행 중...\n",
      "Whisper output (Korean Transcription):  책주 디스크 가슴수출을 영양은 자생환동병연으로 가셨다면 소감영역 6번 출고를 나가시길 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import torch # torch 가용 여부에 따라 device 설정\n",
    "\n",
    "stt_model_name = \"openai/whisper-large-v3-turbo\" # 또는 \"openai/whisper-large-v3\" 사용 권장\n",
    "audio_file_path = \"/Users/gim-yonghyeon/Downloads/광화문자생한방병원_1.mp3\" # 실제 파일 경로로 변경\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"MPS 장치를 사용합니다.\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"CUDA 장치를 사용합니다.\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"CPU를 사용합니다.\")\n",
    "\n",
    "try:\n",
    "    audio_input, sample_rate = sf.read(audio_file_path)\n",
    "    print(f\"오디오 파일 로드 완료: {audio_file_path}, 샘플링 레이트: {sample_rate}\")\n",
    "\n",
    "    if audio_input.ndim > 1: \n",
    "        print(f\"오디오를 모노로 변환 중 (채널 수: {audio_input.shape[1]})\")\n",
    "        audio_input = np.mean(audio_input, axis=1)\n",
    "    \n",
    "    if audio_input.dtype != np.float32:\n",
    "        print(f\"오디오 타입을 np.float32로 변환 중 (현재 타입: {audio_input.dtype})\")\n",
    "        audio_input = audio_input.astype(np.float32)\n",
    "        \n",
    "    # 1. Whisper 파이프라인 생성 (워밍업 전에 생성!)\n",
    "    # 1. Whisper 파이프라인 생성 (워밍업 전에 생성!)\n",
    "    print(f\"Whisper 파이프라인 생성 중 (모델: {stt_model_name}, 장치: {device})...\")\n",
    "    whisper_pipeline = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=stt_model_name,\n",
    "        torch_dtype=torch.float16 if device == \"mps\" else torch.float32,\n",
    "        device=device,\n",
    "        return_timestamps=True  # <--- 여기에도 추가! (스크립트 1과 동일하게)\n",
    "    )\n",
    "    print(\"Whisper 파이프라인 생성 완료.\")\n",
    "\n",
    "    # 2. 워밍업 단계 시작\n",
    "    print(\"\\n🔥 워밍업 단계 시작 (모델 최적화를 위해 몇 차례 실행)...\")\n",
    "    for i in range(2):\n",
    "        print(f\"Warm-up run #{i+1}...\")\n",
    "        # return_timestamps는 파이프라인 생성시 설정했으므로 호출시엔 생략 가능 (또는 일관성 위해 True 전달도 무방)\n",
    "        _ = whisper_pipeline(audio_input.copy()) \n",
    "    print(\"✅ 워밍업 완료\")\n",
    "\n",
    "    # 3. 실제 음성 인식 작업 실행 (한국어 전사)\n",
    "    print(\"\\n🚀 오디오 -> 한국어 전사 작업 실행 중...\")\n",
    "    result = whisper_pipeline(\n",
    "        audio_input.copy()\n",
    "    )\n",
    "    transcribed_text = result['text']\n",
    "    print(f\"Whisper output (Korean Transcription): {transcribed_text}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: 오디오 파일을 찾을 수 없습니다 - {audio_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"스크립트 실행 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbbcde-5fd9-4eaa-87dd-0672f3aea819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stt_project)",
   "language": "python",
   "name": "stt_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
