import base64
import pandas as pd
from pydub import AudioSegment
from dotenv import load_dotenv
from fastapi import UploadFile
from starlette.concurrency import run_in_threadpool
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, AutoModel
from transformers import pipeline
import soundfile as sf
import numpy as np
import io, ssl, whisper, torch, openai, json, os, pycountry, random, re
from typing import Optional, Dict, Any
from kokoro import KPipeline

ssl._create_default_https_context = ssl._create_unverified_context
from stt_project.repository.stt_repository import SttRepository

KOKORO_SUPPORTED_LANGS = ['a', 'b', 'e', 'f', 'h', 'i', 'j', 'p', 'z']
KOKORO_VOICE_PRESETS = {
    'a': ['am_adam', 'am_echo', 'am_eric', 'am_fenrir', 'am_liam', 'am_michael', 'am_onyx', 'am_puck', 'am_santa'],
    'b': ['bf_alice', 'bf_emma', 'bf_isabella', 'bf_lily', 'bm_daniel', 'bm_fable', 'bm_george', 'bm_lewis'],
    'e': ['ef_dora', 'em_alex', 'em_santa'], 'f': ['ff_siwis'], 'h': ['hf_alpha', 'hf_beta', 'hm_omega', 'hm_psi'],
    'i': ['if_sara', 'im_nicola'], 'j': ['jf_alpha', 'jf_gongitsune', 'jf_nezumi', 'jf_tebukuro', 'jm_kumo'],
    'p': ['pf_dora', 'pm_alex', 'pm_santa'],
    'z': ['zf_xiaobei', 'zf_xiaoni', 'zf_xiaoxiao', 'zf_xiaoyi', 'zm_yunjian', 'zm_yunxi', 'zm_yunxia', 'zm_yunyang']
}


class SttRepositoryImpl(SttRepository):
    __instance = None
    load_dotenv()

    def __new__(cls, *args, **kwargs):
        if cls.__instance is None:
            cls.__instance = super().__new__(cls)
        return cls.__instance

    @classmethod
    def getInstance(cls):
        if cls.__instance is None:
            cls.__instance = cls()
        return cls.__instance

    def __init__(self):
        if torch.backends.mps.is_available():
            self.device, self.torch_dtype = torch.device("mps"), torch.bfloat16
        elif torch.cuda.is_available():
            self.device, self.torch_dtype = torch.device("cuda"), torch.bfloat16
        else:
            self.device, self.torch_dtype = torch.device("cpu"), torch.float16

        self.pipelines = {}
        self.gpt_model = None
        self.whisper_detection_model = None
        self.kokoro_tts_pipelines = {}

        self.get_model()
        print("--- SttRepositoryImpl: __init__ ÏµúÏ¥à Ï¥àÍ∏∞Ìôî ÏôÑÎ£å ---")

    def get_model(self):
        model_names_str = os.getenv("STTMODELS", "openai/whisper-large-v3-turbo")
        model_names = [name.strip() for name in model_names_str.split(',') if name.strip()]
        for model_name in model_names:
            try:
                processor = AutoProcessor.from_pretrained(model_name)
                model = AutoModelForSpeechSeq2Seq.from_pretrained(
                    model_name, torch_dtype=self.torch_dtype, low_cpu_mem_usage=(self.device.type == "cpu"),
                    use_safetensors=True
                ).to(self.device)
                self.pipelines[model_name] = pipeline(
                    "automatic-speech-recognition", model=model, tokenizer=processor.tokenizer,
                    feature_extractor=processor.feature_extractor, torch_dtype=self.torch_dtype,
                    device=self.device, return_timestamps=True,
                )
                print(f"‚úÖ Whisper Î™®Îç∏ ({model_name}) Î°úÎìú ÏôÑÎ£å.")
            except Exception as e:
                print(f"‚ùå Whisper Î™®Îç∏ ({model_name}) Î°úÎìú Ï§ë Ïò§Î•ò: {e}")

        openai_api_key = os.getenv("OPENAI_API_KEY")
        self.gpt_model = openai.OpenAI(api_key=openai_api_key) if openai_api_key else None
        if self.gpt_model:
            print("‚úÖ OpenAI GPT ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å.")
        else:
            print("‚ö†Ô∏è OPENAI_API_KEY ÌôòÍ≤Ω Î≥ÄÏàòÍ∞Ä ÏóÜÏñ¥ OpenAI GPT ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Î•º Ï¥àÍ∏∞ÌôîÌï† Ïàò ÏóÜÏäµÎãàÎã§.")

        try:
            self.whisper_detection_model = whisper.load_model("base", device="cpu")
            print("‚úÖ (Ïñ∏Ïñ¥ Í∞êÏßÄÏö©) Whisper Î™®Îç∏ Î°úÎìú ÏôÑÎ£å.")
        except Exception as e:
            print(f"‚ùå (Ïñ∏Ïñ¥ Í∞êÏßÄÏö©) Whisper Î™®Îç∏ Î°úÎìú Ï§ë Ïò§Î•ò: {e}")

        print("--- Kokoro TTS ÏÑ§Ï†ï ÏôÑÎ£å (ÌïÑÏöîÏãú ÎèôÏ†Å Î°úÎìú) ---")
        if not KPipeline:
            print("‚ö†Ô∏è Kokoro ÎùºÏù¥Î∏åÎü¨Î¶¨Í∞Ä ÏóÜÏñ¥ Kokoro TTS Î™®Îç∏ÏùÑ Î°úÎìúÌï† Ïàò ÏóÜÏäµÎãàÎã§.")
        print("--- SttRepositoryImpl: get_model successfully ---")

    def _clean_text_for_speech(self, text: str) -> str:
        """TTS Ìï©ÏÑ±ÏùÑ ÏúÑÌï¥ ÌÖçÏä§Ìä∏ÏóêÏÑú ÎßàÌÅ¨Îã§Ïö¥, Í¥ÑÌò∏, ÌäπÏàò Í∏∞Ìò∏Î•º Ï†úÍ±∞Ìï©ÎãàÎã§."""
        if not text: return ""
        cleaned_text = text.replace('**', '').replace('*', '')
        cleaned_text = cleaned_text.replace('‚Üí', ' ')
        cleaned_text = re.sub(r'#+\s', '', cleaned_text)
        # Í¥ÑÌò∏ÏôÄ Í∑∏ ÏïàÏùò ÎÇ¥Ïö© (Ï£ºÎ°ú ÏòÅÏñ¥ ÎòêÎäî Î∂ÄÍ∞Ä ÏÑ§Î™Ö)ÏùÑ ÌÜµÏß∏Î°ú Ï†úÍ±∞
        cleaned_text = re.sub(r'\s*\(.*?\)\s*', ' ', cleaned_text)
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
        return cleaned_text

    def universal_translation_sync(self, text_to_translate: str, source_lang: str, target_lang: str) -> str:
        if not self.gpt_model: return "GPT Î≤àÏó≠ ÏÑúÎπÑÏä§ ÏÇ¨Ïö© Î∂àÍ∞Ä"
        if not text_to_translate or not text_to_translate.strip(): return ""
        system_content = f"You are a professional translator. Your task is to accurately translate the given text from {source_lang} to {target_lang}. Preserve the original formatting and meaning. Provide only the translated text, without any introductory phrases."
        messages = [{"role": "system", "content": system_content}, {"role": "user",
                                                                    "content": f"Translate the following text from {source_lang} to {target_lang}:\n\n{text_to_translate}"}]
        try:
            completion = self.gpt_model.chat.completions.create(model="gpt-4o-mini", messages=messages, temperature=0.0)
            return completion.choices[0].message.content.strip()
        except Exception as e:
            print(f"‚ùå OpenAI GPT Î≤àÏó≠ Ï§ë Ïò§Î•ò: {e}")
            return f"GPT Î≤àÏó≠ Ïò§Î•ò: {e}"

    def generate_llm_response_sync(self, text_input: str, original_language_code: str) -> dict:
        default_answers = {"answer_original_language": "ÎãµÎ≥Ä ÏÉùÏÑ± Ïã§Ìå®", "answer_korean": "ÎãµÎ≥Ä ÏÉùÏÑ± Ïã§Ìå®"}
        if not self.gpt_model:
            default_answers["answer_original_language"] = "OpenAI API ÏÇ¨Ïö© Î∂àÍ∞Ä"
            default_answers["answer_korean"] = "OpenAI API ÏÇ¨Ïö© Î∂àÍ∞Ä"
            return default_answers
        if not text_input or text_input.strip() == "":
            default_answers["answer_original_language"] = "ÏûÖÎ†• ÌÖçÏä§Ìä∏ ÏóÜÏùå"
            default_answers["answer_korean"] = "ÏûÖÎ†• ÌÖçÏä§Ìä∏ ÏóÜÏùå"
            return default_answers

        original_lang_name_en = original_language_code
        try:
            lang_obj = pycountry.languages.get(alpha_2=original_language_code.split('-')[0].lower())
            if lang_obj: original_lang_name_en = lang_obj.name
        except:
            pass

        system_prompt = f"""You are an AI expert specializing in South Korean public transportation.
        Your primary role is to provide the most optimal travel route from a starting point to a destination within South Korea, in {original_lang_name_en}.

        Always follow these steps to structure your response:
        1.  Propose one "Recommended Route" that is the most efficient, considering a balance of travel time, number of transfers, and cost.
        2.  Describe each step of the Recommended Route in detail (e.g., walking, subway line, bus number, direction, travel time, getting off station, exit number).
        3.  You can also suggest one or two "Alternative Routes" that might be worth considering.
        4.  Conclude with a summary of the "Estimated Total Time" and "Estimated Fare".
        5.  Provide only the helpful answer, without any introductory phrases like "Of course, here is the route...".
        6.  IMPORTANT for non-English responses: Provide the response purely in the target language ({original_lang_name_en}). Do not include English text, romanizations, or explanations in parentheses. For example, instead of "Â†ÇÂ±± (Dangsan)", just write "Â†ÇÂ±±". Instead of writing durations like "(Approx. 10 min)", integrate the time naturally into the sentence in the target language.
        """

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": text_input}
        ]
        try:
            completion = self.gpt_model.chat.completions.create(model="gpt-4o", messages=messages, temperature=0.7)
            original_language_answer = completion.choices[0].message.content.strip()
            korean_answer = self.universal_translation_sync(original_language_answer, original_lang_name_en, "Korean")
            return {"answer_original_language": original_language_answer, "answer_korean": korean_answer}
        except Exception as e:
            print(f"‚ùå OpenAI GPT ÎãµÎ≥Ä ÏÉùÏÑ±/Î≤àÏó≠ Ï§ë Ïò§Î•ò: {e}")
            return default_answers

    def generate_speech_sync(self, text: str, lang_code: str) -> Optional[bytes]:
        if not KPipeline:
            print("‚ö†Ô∏è Kokoro ÎùºÏù¥Î∏åÎü¨Î¶¨Í∞Ä ÏóÜÏñ¥ TTS ÏÉùÏÑ±ÏùÑ Í±¥ÎÑàÏåâÎãàÎã§.")
            return None
        if not text or not text.strip():
            return None

        kokoro_lang_code_map = {
            'en': 'a', 'es': 'e', 'fr': 'f', 'hi': 'h', 'it': 'i', 'ja': 'j', 'pt': 'p', 'zh': 'z'
        }
        kokoro_lang_char = kokoro_lang_code_map.get(lang_code.split('-')[0].lower())

        if kokoro_lang_char is None or kokoro_lang_char not in KOKORO_SUPPORTED_LANGS:
            print(f"‚ö†Ô∏è Kokoro TTSÎäî '{lang_code}' Ïñ∏Ïñ¥Ïóê ÎåÄÌïú ÏùåÏÑ± ÏÉùÏÑ±ÏùÑ ÏßÄÏõêÌïòÏßÄ ÏïäÏäµÎãàÎã§.")
            return None

        if kokoro_lang_char not in self.kokoro_tts_pipelines:
            print(f"üîß Kokoro TTS ÌååÏù¥ÌîÑÎùºÏù∏ ('{kokoro_lang_char}' / {lang_code})ÏùÑ Ï≤òÏùå Î°úÎìúÌï©ÎãàÎã§...")
            try:
                self.kokoro_tts_pipelines[kokoro_lang_char] = KPipeline(lang_code=kokoro_lang_char)
                print(f"‚úÖ Kokoro TTS ÌååÏù¥ÌîÑÎùºÏù∏ ('{kokoro_lang_char}') Î°úÎìú Î∞è Ï†ÄÏû• ÏôÑÎ£å.")
            except Exception as e:
                print(f"‚ùå Kokoro TTS ÌååÏù¥ÌîÑÎùºÏù∏ ('{kokoro_lang_char}') Î°úÎìú Ïã§Ìå®: {e}")
                return None

        tts_pipeline = self.kokoro_tts_pipelines[kokoro_lang_char]

        available_voice_presets = KOKORO_VOICE_PRESETS.get(kokoro_lang_char)
        if not available_voice_presets:
            print(f"‚ö†Ô∏è Ïñ∏Ïñ¥ ÏΩîÎìú '{kokoro_lang_char}'Ïóê ÎåÄÌïú Kokoro ÏùåÏÑ± ÌîÑÎ¶¨ÏÖãÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
            return None

        voice_preset = random.choice(available_voice_presets)
        print(f"\n--- üîä Kokoro TTS ÏÉùÏÑ± ÏãúÏûë (Ïñ∏Ïñ¥: {lang_code}, Kokoro ÏΩîÎìú: '{kokoro_lang_char}', ÌîÑÎ¶¨ÏÖã: {voice_preset}) ---")
        try:
            # Ï†ïÏ†úÎêú ÌÖçÏä§Ìä∏Î•º TTS ÏóîÏßÑÏóê Ï†ÑÎã¨
            generator = tts_pipeline(text, voice=voice_preset)
            all_audio_arrays = [audio_chunk for _, _, audio_chunk in generator]

            if not all_audio_arrays:
                print("‚ùå Kokoro TTSÏóêÏÑú Ïò§ÎîîÏò§ Ï≤≠ÌÅ¨Î•º Î∞õÏßÄ Î™ªÌñàÏäµÎãàÎã§.")
                return None

            combined_audio_array = np.concatenate(all_audio_arrays)
            buffer = io.BytesIO()
            sf.write(buffer, combined_audio_array, 24000, format='WAV')
            buffer.seek(0)
            return buffer.read()
        except Exception as e:
            print(f"‚ùå Kokoro TTS ÏÉùÏÑ± Ï§ë Ïò§Î•ò: {e}")
            import traceback;
            traceback.print_exc()
            return None

    async def transcription(self, audio_file: UploadFile, model_name: str) -> Dict[str, Any]:
        default_response = {"text": "", "language_code": "unknown", "language_name": "Unknown",
                            "language_probability": 0.0, "original_query": "", "korean_query": "",
                            "original_language_answer": "", "korean_answer": "", "korean_answer_audio_base64": None,
                            "original_language_answer_audio_base64": None}
        try:
            target_pipe = self.pipelines.get(model_name)
            if not target_pipe:
                return {**default_response, "error": "ModelNotFoundError",
                        "message": f"ÏöîÏ≤≠Ìïú Î™®Îç∏ '{model_name}'ÏùÑ ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§."}

            audio_bytes = await audio_file.read()
            try:
                audio_array, sampling_rate = sf.read(io.BytesIO(audio_bytes))
            except sf.LibsndfileError:
                try:
                    audio_segment = AudioSegment.from_file(io.BytesIO(audio_bytes)).set_frame_rate(16000).set_channels(
                        1)
                    audio_array = np.array(audio_segment.get_array_of_samples()).astype(np.float32) / 32768.0
                    sampling_rate = audio_segment.frame_rate
                except Exception as e_pydub:
                    return {**default_response, "error": "AudioProcessingError", "message": f"Ïò§ÎîîÏò§ ÌååÏùº Ï≤òÎ¶¨ Ïò§Î•ò: {e_pydub}"}

            if audio_array.ndim > 1: audio_array = np.mean(audio_array, axis=1)
            loaded_audio_sample = {"array": audio_array.astype(np.float32), "sampling_rate": sampling_rate}

            language_info = {"code": "unknown", "name": "Unknown", "probability": 0.0}
            if self.whisper_detection_model:
                try:
                    trimmed_audio = whisper.pad_or_trim(loaded_audio_sample['array'])
                    mel = whisper.log_mel_spectrogram(trimmed_audio).to(self.whisper_detection_model.device)
                    _, probs = self.whisper_detection_model.detect_language(mel)
                    original_lang_code = max(probs, key=probs.get)
                    lang_name = pycountry.languages.get(alpha_2=original_lang_code).name if pycountry.languages.get(
                        alpha_2=original_lang_code) else original_lang_code
                    language_info.update({'code': original_lang_code, 'name': lang_name,
                                          'probability': round(probs[original_lang_code], 2)})
                    print(f"‚úÖ Í∞êÏßÄÎêú Ïñ∏Ïñ¥: '{original_lang_code}' (ÌôïÎ•†: {language_info['probability']})")
                except Exception as e:
                    print(f"‚ö†Ô∏è Ïñ∏Ïñ¥ Í∞êÏßÄ Ï§ë Ïò§Î•ò: {e}")

            generate_kwargs = {"language": language_info['code']} if language_info['code'] != 'unknown' else {}
            result = await run_in_threadpool(target_pipe, loaded_audio_sample.copy(), generate_kwargs=generate_kwargs)
            transcribed_text = result.get("text", "").strip()

            translated_question_korean = ""
            if transcribed_text and language_info['code'] != 'ko':
                translated_question_korean = await run_in_threadpool(self.universal_translation_sync, transcribed_text,
                                                                     language_info['name'], "Korean")
            elif language_info['code'] == 'ko':
                translated_question_korean = transcribed_text

            llm_answers = {"answer_original_language": "ÎØ∏Ïã§Ìñâ", "answer_korean": "ÎØ∏Ïã§Ìñâ"}
            if transcribed_text and language_info['code'] != 'unknown':
                llm_answers = await run_in_threadpool(self.generate_llm_response_sync, transcribed_text,
                                                      language_info['code'])

            original_audio_base64 = None
            original_answer_text = llm_answers.get("answer_original_language")
            if original_answer_text and original_answer_text not in ["ÎØ∏Ïã§Ìñâ", "ÎãµÎ≥Ä ÏÉùÏÑ± Ïã§Ìå®"] and language_info[
                'code'] != 'ko':
                cleaned_text_for_tts = self._clean_text_for_speech(original_answer_text)
                original_audio_bytes = await run_in_threadpool(self.generate_speech_sync, cleaned_text_for_tts,
                                                               language_info['code'])
                if original_audio_bytes:
                    original_audio_base64 = base64.b64encode(original_audio_bytes).decode('utf-8')

            final_response = {
                "original_query": transcribed_text,
                "language_code": language_info['code'],
                "language_name": language_info['name'],
                "language_probability": language_info['probability'],
                "korean_query": translated_question_korean,
                "original_language_answer": llm_answers.get("answer_original_language"),
                "korean_answer": llm_answers.get("answer_korean"),
                "korean_answer_audio_base64": None,
                "original_language_answer_audio_base64": original_audio_base64
            }
            return final_response

        except Exception as e:
            import traceback
            traceback.print_exc()
            return {**default_response, "error": "TranscriptionProcessError", "message": f"ÏùåÏÑ± Ïù∏Ïãù Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {e}"}